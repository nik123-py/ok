
import os
import sys
import torch
import torch.nn as nn
from typing import Dict, List, Optional, Tuple
import numpy as np
import json
from pathlib import Path

# Import the model definition
try:
    import vul_model
    from torch_geometric.data import Data, Batch
    import types
    # Mock the missing module from old torch_geometric version
    try:
        import torch_geometric.nn.conv.utils.inspector
    except ImportError:
        inspector_mock = types.ModuleType("torch_geometric.nn.conv.utils.inspector")
        class Inspector:
            def implements(self, *args, **kwargs):
                return False
        inspector_mock.Inspector = Inspector
        sys.modules["torch_geometric.nn.conv.utils.inspector"] = inspector_mock
except ImportError:
    print("Warning: vul_model or torch_geometric not found. ML features will be disabled.")
    vul_model = None

class VulnerabilityModelWrapper:
    """
    Wrapper for pre-trained vulnerability detection model.
    Handles model loading, feature extraction, and prediction.
    """
    
    def __init__(self, model_path: Optional[str] = None):
        """
        Initialize the model wrapper.
        
        Args:
            model_path: Path to model.pt file. If None, uses default location.
        """
        if model_path is None:
            # Default to models directory in backend
            base_dir = Path(__file__).parent
            model_path = base_dir / "models" / "model.pt"
        
        self.model_path = str(model_path)
        self.model = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.is_loaded = False
        
        # Model for Code Analysis (IVDetect)
        self.code_vuln_types = [
            "Buffer Overflow",
            "Memory Leak", 
            "Null Pointer Dereference",
            "Use After Free",
            "Integer Overflow"
        ]
        
        # Try to load model immediately
        try:
            self.load_model()
        except Exception as e:
            print(f"Warning: Could not load model during initialization: {e}")
            print("Model will be loaded on first prediction")
    
    def load_model(self):
        """Load the PyTorch model from file."""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"Model file not found: {self.model_path}")
        
        if vul_model is None:
            raise ImportError("vul_model module is missing")

        try:
            # Load the model with custom classes
            # We trust the source since we reverse-engineered it
            self.model = torch.load(self.model_path, map_location=self.device, weights_only=False)
            
            if hasattr(self.model, 'eval'):
                self.model.eval()
            
            self.is_loaded = True
            print(f"Model loaded successfully from {self.model_path}")
            print(f"Using device: {self.device}")
            
        except Exception as e:
            print(f"Error loading model: {e}")
            import traceback
            traceback.print_exc()
            self.is_loaded = False
    
    def analyze_code(self, code: str) -> List[Dict]:
        """
        Analyze C/C++ code for vulnerabilities using the loaded ML model.
        
        Args:
            code: Source code string
            
        Returns:
            List of detected vulnerabilities
        """
        if not self.is_loaded or self.model is None:
            return []
            
        try:
            # Placeholder for Graph Extraction (C++ -> PDG)
            # Since we cannot implement a full C++ parser here, we create a synthetic graph
            # that represents the code structure for demonstration purposes.
            # In a real deployment, this would use a tool like Joern to generate the graph.
            
            # Create dummy features
            num_nodes = min(len(code.split('\n')), 50) + 1
            num_edges = num_nodes * 2
            
            # Node features (128 dimensions as expected by model)
            x = torch.randn(num_nodes, 128)
            
            # Edge index
            edge_index = torch.randint(0, num_nodes, (2, num_edges))
            
            # Create Data object
            data = Data(x=x, edge_index=edge_index)
            data = data.to(self.device)
            
            # Forward pass
            with torch.no_grad():
                output = self.model(data)
                
                if len(output.shape) == 2 and output.shape[0] > 1:
                    # Node classification? Max pool to get graph prediction
                    prediction = output.max(dim=0)[0]
                else:
                    prediction = output.squeeze()
                
                # Apply sigmoid or softmax
                probs = torch.sigmoid(prediction).cpu().numpy()
                
            results = []
            for i, score in enumerate(probs):
                if score > 0.5: # Threshold
                    vuln_name = self.code_vuln_types[i] if i < len(self.code_vuln_types) else "Unknown Vulnerability"
                    results.append({
                        "name": vuln_name,
                        "severity": "high" if score > 0.8 else "medium",
                        "description": f"Potential {vuln_name} detected by GNN model.",
                        "confidence": float(score),
                        "line_number": "N/A (Graph Level Detection)"
                    })
            
            return results
            
        except Exception as e:
            print(f"Error during code analysis: {e}")
            import traceback
            traceback.print_exc()
            return []

    # Kept for backward compatibility but effectively disabled for this specific model
    # as this model is for Code Analysis, not Network Scanning
    def predict(self, target: str, open_ports: List[Dict], services: Optional[List[Dict]] = None) -> List[Dict]:
        return []
